{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badc685b",
   "metadata": {},
   "source": [
    "# ðŸŒ³ Tutorial Completo: Ãrbol de DecisiÃ³n para ClasificaciÃ³n\n",
    "\n",
    "Este notebook contiene un flujo completo de Machine Learning usando **Ãrboles de DecisiÃ³n** para clasificaciÃ³n binaria.\n",
    "\n",
    "## ðŸ“‹ Contenido:\n",
    "1. ImportaciÃ³n de librerÃ­as\n",
    "2. Carga y preparaciÃ³n de datos\n",
    "3. Preprocesamiento (opcional segÃºn tu dataset)\n",
    "4. DivisiÃ³n de datos\n",
    "5. Entrenamiento del modelo\n",
    "6. OptimizaciÃ³n de hiperparÃ¡metros\n",
    "7. EvaluaciÃ³n y visualizaciones\n",
    "8. AnÃ¡lisis avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b44a1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ PASO 1: Importar LibrerÃ­as Necesarias\n",
    "\n",
    "**Â¿QuÃ© hace?** Importa todas las librerÃ­as que usaremos durante el anÃ¡lisis.\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Siempre necesario al inicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LibrerÃ­as bÃ¡sicas para manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# LibrerÃ­as de scikit-learn para el modelo y divisiÃ³n de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# LibrerÃ­as para evaluaciÃ³n y mÃ©tricas\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "                             PrecisionRecallDisplay, classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d7182",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ PASO 2: Cargar y Preparar el Dataset\n",
    "\n",
    "**Â¿QuÃ© hace?** \n",
    "- Lee el archivo CSV con los datos\n",
    "- Separa las **variables independientes (X)** de la **variable objetivo (y)**\n",
    "\n",
    "**ParÃ¡metros a modificar:**\n",
    "- `\"diabetes.csv\"` â†’ Cambia esto por el nombre de tu archivo\n",
    "- `\"Outcome\"` â†’ Cambia esto por el nombre de tu columna objetivo\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Necesitas cargar tus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEER ARCHIVO CSV\n",
    "# ðŸ“ MODIFICAR: Cambia \"diabetes.csv\" por el nombre de tu archivo\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# IDENTIFICAR COLUMNA OBJETIVO (la que queremos predecir)\n",
    "# ðŸ“ MODIFICAR: Cambia \"Outcome\" por el nombre de tu columna objetivo\n",
    "y = df[\"Outcome\"]  # Variable dependiente (lo que queremos predecir)\n",
    "\n",
    "# ELIMINAR COLUMNA OBJETIVO del conjunto de caracterÃ­sticas\n",
    "X = df.drop(columns=[\"Outcome\"])  # Variables independientes (features)\n",
    "\n",
    "# MOSTRAR LA SEPARACIÃ“N para verificar\n",
    "display(y.head())  # Primeros valores de la variable objetivo\n",
    "display(X.head())  # Primeras filas de las caracterÃ­sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4dac0",
   "metadata": {},
   "source": [
    "### ðŸ“Œ MÃ‰TODO ALTERNATIVO: SelecciÃ³n por Ãndices\n",
    "\n",
    "**Obligatorio:** âŒ NO - Solo si prefieres seleccionar columnas por posiciÃ³n en lugar de por nombre.\n",
    "\n",
    "**Â¿CuÃ¡ndo usar?** Si no tienes nombres de columnas o prefieres trabajar con Ã­ndices numÃ©ricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b715be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTRA FORMA DE OBTENER VARIABLES (usando Ã­ndices)\n",
    "# X = df.iloc[:, 0:8].values   # Toma columnas 0 a 7 (todas las caracterÃ­sticas)\n",
    "# y = df.iloc[:, -1].values     # Toma la Ãºltima columna (objetivo)\n",
    "\n",
    "# ðŸ“ MODIFICAR:\n",
    "# - 0:8 â†’ Cambia por el rango de tus columnas de caracterÃ­sticas\n",
    "# - -1 â†’ Mantener si tu objetivo estÃ¡ en la Ãºltima columna, sino cambia el Ã­ndice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7567b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ PASO 3: CodificaciÃ³n de Variables CategÃ³ricas (Variables Dummies)\n",
    "\n",
    "**Obligatorio:** âŒ NO - **SOLO si tienes variables categÃ³ricas (texto) en tu dataset**\n",
    "\n",
    "**Â¿CuÃ¡ndo usar?**\n",
    "- Si tienes columnas con valores como: \"Masculino/Femenino\", \"Alto/Medio/Bajo\", etc.\n",
    "- Si todas tus columnas ya son numÃ©ricas, **SALTA ESTA CELDA**\n",
    "\n",
    "**âš ï¸ ADVERTENCIA:** El cÃ³digo actual tiene errores. AquÃ­ estÃ¡ la versiÃ³n corregida.\n",
    "\n",
    "**ParÃ¡metros:**\n",
    "- `[3]` â†’ Ãndice de la columna categÃ³rica a convertir (cambia segÃºn tu dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb58470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ ESTA CELDA ES OPCIONAL - Solo si tienes variables categÃ³ricas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Supongamos que la columna 3 es categÃ³rica (ej: \"Alto\", \"Medio\", \"Bajo\")\n",
    "# ðŸ“ MODIFICAR: Cambia [3] por el Ã­ndice de tu columna categÃ³rica\n",
    "\n",
    "# Convertir X a numpy array si es DataFrame\n",
    "X_array = X.values\n",
    "\n",
    "# Codificar la columna categÃ³rica a nÃºmeros\n",
    "labelencoder_X = LabelEncoder()\n",
    "X_array[:, 3] = labelencoder_X.fit_transform(X_array[:, 3])\n",
    "\n",
    "# Aplicar One-Hot Encoding (crear variables dummy)\n",
    "onehotencoder = make_column_transformer(\n",
    "    (OneHotEncoder(), [3]),  # Columna a codificar\n",
    "    remainder=\"passthrough\"  # Mantener las demÃ¡s columnas sin cambios\n",
    ")\n",
    "X = onehotencoder.fit_transform(X_array)\n",
    "\n",
    "# ELIMINAR la primera columna dummy para evitar multicolinealidad (Dummy Variable Trap)\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ba77f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ PASO 4: Escalado de Variables (NormalizaciÃ³n/EstandarizaciÃ³n)\n",
    "\n",
    "**Obligatorio:** âš ï¸ DEPENDE\n",
    "\n",
    "**Â¿CuÃ¡ndo usar?**\n",
    "- **SÃ necesario** para: SVM, KNN, RegresiÃ³n LogÃ­stica, Redes Neuronales\n",
    "- **NO necesario** para: Ãrboles de DecisiÃ³n, Random Forest, XGBoost\n",
    "\n",
    "Para **Ãrboles de DecisiÃ³n** (nuestro caso) puedes **SALTAR** esta celda, pero no hace daÃ±o aplicarlo.\n",
    "\n",
    "**Â¿QuÃ© hace?** Escala las variables para que tengan media 0 y desviaciÃ³n estÃ¡ndar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dca498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ ESTA CELDA ES OPCIONAL para Ãrboles de DecisiÃ³n\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos escalados (primeras 5 filas):\")\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184d141",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ PASO 5: Dividir los Datos en Entrenamiento y Prueba\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Fundamental para evaluar el modelo correctamente.\n",
    "\n",
    "**ParÃ¡metros importantes:**\n",
    "\n",
    "### ðŸ”§ `test_size` (TamaÃ±o del conjunto de prueba)\n",
    "- **Valor:** 0.25 (25% prueba, 75% entrenamiento)\n",
    "- **Recomendaciones segÃºn tamaÃ±o del dataset:**\n",
    "  - Dataset GRANDE (>10,000 filas): `0.10` a `0.20` (10-20%)\n",
    "  - Dataset MEDIANO (1,000-10,000): `0.20` a `0.30` (20-30%)\n",
    "  - Dataset PEQUEÃ‘O (<1,000): `0.30` a `0.40` (30-40%)\n",
    "\n",
    "### ðŸ”§ `random_state`\n",
    "- **Valor:** 42 (puede ser cualquier nÃºmero)\n",
    "- **PropÃ³sito:** Hace que la divisiÃ³n sea reproducible (siempre igual)\n",
    "\n",
    "### ðŸ”§ `stratify`\n",
    "- **Valor:** `y` (la variable objetivo)\n",
    "- **PropÃ³sito:** Mantiene la misma proporciÃ³n de clases en entrenamiento y prueba\n",
    "- **Ejemplo:** Si tienes 60% clase 0 y 40% clase 1, ambos conjuntos tendrÃ¡n esa proporciÃ³n\n",
    "\n",
    "### ðŸ”§ `shuffle` (no usado aquÃ­, pero disponible)\n",
    "- **Valor por defecto:** `True`\n",
    "- **PropÃ³sito:** Mezcla los datos antes de dividir\n",
    "- **CuÃ¡ndo usar False:** Solo si tus datos tienen orden temporal importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38232b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDIR LA DATA en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,      # ðŸ“ MODIFICAR: 25% para prueba, 75% para entrenar\n",
    "    random_state=42,     # ðŸ“ MODIFICAR: Cualquier nÃºmero para reproducibilidad\n",
    "    stratify=y           # Mantiene proporciones de clases balanceadas\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]} filas\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]} filas\")\n",
    "print(f\"\\nDistribuciÃ³n de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nDistribuciÃ³n de clases en prueba:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa14d1",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ PASO 6: Crear y Entrenar el Modelo (VersiÃ³n BÃ¡sica)\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Este es el corazÃ³n del anÃ¡lisis.\n",
    "\n",
    "**ParÃ¡metros del DecisionTreeClassifier:**\n",
    "\n",
    "### ðŸ”§ `criterion` (Criterio de divisiÃ³n)\n",
    "- **Opciones:** `\"gini\"`, `\"entropy\"`, `\"log_loss\"`\n",
    "- **Por defecto:** `\"gini\"`\n",
    "- **Gini:** MÃ¡s rÃ¡pido, usado comÃºnmente\n",
    "- **Entropy:** Basado en teorÃ­a de informaciÃ³n, puede ser mÃ¡s preciso\n",
    "- **Log_loss:** Similar a entropy, Ãºtil en algunos casos\n",
    "\n",
    "### ðŸ”§ `max_depth` (Profundidad mÃ¡xima del Ã¡rbol)\n",
    "- **Opciones:** Cualquier entero positivo o `None`\n",
    "- **Por defecto:** `None` (sin lÃ­mite)\n",
    "- **Recomendado:** 3-10 para evitar sobreajuste\n",
    "- **Menor profundidad:** Modelo mÃ¡s simple, menos sobreajuste\n",
    "- **Mayor profundidad:** Modelo mÃ¡s complejo, puede sobreajustar\n",
    "\n",
    "### ðŸ”§ `random_state` (Semilla aleatoria)\n",
    "- **Valor:** Cualquier entero\n",
    "- **PropÃ³sito:** Reproducibilidad de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR EL MODELO DE ÃRBOL DE DECISIÃ“N (versiÃ³n bÃ¡sica con parÃ¡metros por defecto)\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# ParÃ¡metros opcionales que puedes agregar:\n",
    "# criterion=\"gini\",        # ðŸ“ MODIFICAR: \"gini\", \"entropy\", o \"log_loss\"\n",
    "# max_depth=4,             # ðŸ“ MODIFICAR: NÃºmero entre 2-10, o None para sin lÃ­mite\n",
    "# random_state=42          # ðŸ“ MODIFICAR: Para reproducibilidad\n",
    "\n",
    "print(\"Modelo creado con parÃ¡metros por defecto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAR EL MODELO con los datos de entrenamiento\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Modelo entrenado exitosamente\")\n",
    "print(f\"Profundidad del Ã¡rbol: {tree.get_depth()}\")\n",
    "print(f\"NÃºmero de hojas: {tree.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACER PREDICCIONES con los datos de prueba\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"Predicciones realizadas:\")\n",
    "print(y_pred[:10])  # Mostrar las primeras 10 predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUAR LA PRECISIÃ“N del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"ðŸ“Š PrecisiÃ³n del modelo: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8d0ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ PASO 7: OptimizaciÃ³n de HiperparÃ¡metros con GridSearchCV\n",
    "\n",
    "**Obligatorio:** âŒ NO - Pero **MUY RECOMENDADO** para mejorar el rendimiento.\n",
    "\n",
    "**Â¿QuÃ© hace?** Prueba todas las combinaciones de parÃ¡metros para encontrar la mejor.\n",
    "\n",
    "**ParÃ¡metros de GridSearchCV:**\n",
    "\n",
    "### ðŸ”§ `param_grid` (Diccionario de parÃ¡metros a probar)\n",
    "- Define quÃ© valores probar para cada parÃ¡metro\n",
    "- **MÃ¡s opciones = MÃ¡s tiempo de ejecuciÃ³n**\n",
    "\n",
    "### ðŸ”§ `cv` (Cross-validation)\n",
    "- **Valor:** NÃºmero de \"folds\" (divisiones)\n",
    "- **ComÃºn:** 5 o 10\n",
    "- **Mayor valor:** MÃ¡s preciso pero mÃ¡s lento\n",
    "\n",
    "### ðŸ”§ `n_jobs`\n",
    "- **Valor:** -1 (usar todos los procesadores)\n",
    "- **PropÃ³sito:** Acelerar el proceso usando paralelizaciÃ³n\n",
    "\n",
    "### ðŸ”§ `scoring`\n",
    "- **Opciones:** \"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\"\n",
    "- **Por defecto:** \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIR PARÃMETROS A PROBAR\n",
    "param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],  # ðŸ“ MODIFICAR: Criterios a probar\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, None],  # ðŸ“ MODIFICAR: Profundidades a probar\n",
    "}\n",
    "\n",
    "# NOTA: Puedes agregar mÃ¡s parÃ¡metros:\n",
    "# \"min_samples_split\": [2, 5, 10],      # MÃ­nimo de muestras para dividir un nodo\n",
    "# \"min_samples_leaf\": [1, 2, 5],        # MÃ­nimo de muestras en cada hoja\n",
    "# \"max_features\": [None, \"sqrt\", \"log2\"] # NÃºmero mÃ¡ximo de caracterÃ­sticas a considerar\n",
    "\n",
    "print(f\"Se probarÃ¡n {len(param_dist['criterion']) * len(param_dist['max_depth'])} combinaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR Y EJECUTAR GRID SEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    tree,\n",
    "    param_grid=param_dist,\n",
    "    cv=15,              # ðŸ“ MODIFICAR: NÃºmero de folds (comÃºn: 5 o 10)\n",
    "    n_jobs=-1,          # Usar todos los procesadores disponibles\n",
    "    scoring=\"accuracy\"  # ðŸ“ MODIFICAR: MÃ©trica a optimizar\n",
    ")\n",
    "\n",
    "print(\"â³ Buscando mejores parÃ¡metros... (esto puede tardar)\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"âœ… BÃºsqueda completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c977795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER EL MEJOR ESTIMADOR ENCONTRADO\n",
    "print(\"ðŸ† Mejor modelo encontrado:\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER EL MEJOR SCORE (precisiÃ³n)\n",
    "print(f\"ðŸ“Š Mejor score (accuracy): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER LOS MEJORES PARÃMETROS\n",
    "print(\"âš™ï¸ Mejores parÃ¡metros encontrados:\")\n",
    "for param, value in grid.best_params_.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db61dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 8ï¸âƒ£ PASO 8: Entrenar Modelo Final con Mejores ParÃ¡metros\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Si hiciste GridSearch, usa los mejores parÃ¡metros encontrados.\n",
    "\n",
    "**Â¿QuÃ© hace?** Crea un nuevo modelo con los parÃ¡metros Ã³ptimos y lo evalÃºa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd94639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR MODELO CON LOS MEJORES PARÃMETROS\n",
    "# ðŸ“ MODIFICAR: Usa los valores que obteniste de grid.best_params_\n",
    "\n",
    "tree_optimized = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",    # ðŸ“ Usar el valor de best_params_\n",
    "    max_depth=8,         # ðŸ“ Usar el valor de best_params_\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "tree_optimized.fit(X_train, y_train)\n",
    "\n",
    "# PREDECIR\n",
    "y_pred_optimized = tree_optimized.predict(X_test)\n",
    "\n",
    "# EVALUAR\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"ðŸ“Š PrecisiÃ³n del modelo optimizado: {accuracy_optimized:.4f} ({accuracy_optimized*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706e024",
   "metadata": {},
   "source": [
    "---\n",
    "## 9ï¸âƒ£ PASO 9: VisualizaciÃ³n de MÃ©tricas - Matriz de ConfusiÃ³n\n",
    "\n",
    "**Obligatorio:** âš ï¸ RECOMENDADO - Esencial para entender el rendimiento del modelo.\n",
    "\n",
    "**Â¿QuÃ© muestra?**\n",
    "- **Verdaderos Positivos (VP):** Predicciones correctas de clase 1\n",
    "- **Verdaderos Negativos (VN):** Predicciones correctas de clase 0\n",
    "- **Falsos Positivos (FP):** Predicciones incorrectas como clase 1\n",
    "- **Falsos Negativos (FN):** Predicciones incorrectas como clase 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559dd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MATRIZ DE CONFUSIÃ“N\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    tree_optimized,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    ax=ax,\n",
    "    cmap=\"Blues\"  # ðŸ“ MODIFICAR: Color (\"Blues\", \"Greens\", \"Reds\", \"Purples\")\n",
    ")\n",
    "ax.set_title(\"Matriz de ConfusiÃ³n â€” Ãrbol de DecisiÃ³n Optimizado\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# REPORTE DE CLASIFICACIÃ“N (mÃ©tricas detalladas)\n",
    "print(\"\\nðŸ“‹ Reporte de ClasificaciÃ³n:\")\n",
    "print(classification_report(y_test, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc35f06",
   "metadata": {},
   "source": [
    "**ðŸ“– InterpretaciÃ³n del Reporte:**\n",
    "- **Precision:** De todas las predicciones positivas, Â¿cuÃ¡ntas fueron correctas?\n",
    "- **Recall (Sensibilidad):** De todos los positivos reales, Â¿cuÃ¡ntos detectamos?\n",
    "- **F1-Score:** Media armÃ³nica de Precision y Recall\n",
    "- **Support:** NÃºmero de muestras de cada clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f9fb9",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ”Ÿ PASO 10: Curvas ROC y Precision-Recall\n",
    "\n",
    "**Obligatorio:** âš ï¸ RECOMENDADO - Muy Ãºtil para evaluar modelos de clasificaciÃ³n.\n",
    "\n",
    "**Curva ROC:**\n",
    "- Muestra la relaciÃ³n entre Tasa de Verdaderos Positivos vs Falsos Positivos\n",
    "- **AUC (Area Under Curve):** MÃ©trica resumen (0.5 = aleatorio, 1.0 = perfecto)\n",
    "\n",
    "**Curva Precision-Recall:**\n",
    "- Ãštil cuando las clases estÃ¡n desbalanceadas\n",
    "- Muestra el balance entre Precision y Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURVA ROC\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "RocCurveDisplay.from_estimator(tree_optimized, X_test, y_test, ax=ax)\n",
    "ax.set_title(\"Curva ROC\")\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')  # LÃ­nea diagonal\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# CURVA PRECISION-RECALL\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "PrecisionRecallDisplay.from_estimator(tree_optimized, X_test, y_test, ax=ax)\n",
    "ax.set_title(\"Curva Precisionâ€“Recall\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86a62b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£1ï¸âƒ£ PASO 11: Importancia de Variables\n",
    "\n",
    "**Obligatorio:** âŒ NO - Pero muy Ãºtil para interpretar el modelo.\n",
    "\n",
    "**Â¿QuÃ© muestra?** QuÃ© caracterÃ­sticas (variables) son mÃ¡s importantes para las predicciones del Ã¡rbol.\n",
    "\n",
    "**âš ï¸ NOTA:** Esta celda requiere que `X` sea un DataFrame con nombres de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f474d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANCIA DE VARIABLES\n",
    "importances = tree_optimized.feature_importances_\n",
    "\n",
    "# Obtener nombres de caracterÃ­sticas (ajustar segÃºn tu caso)\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feat_names = X.columns.to_numpy()\n",
    "else:\n",
    "    # Si X no es DataFrame, crear nombres genÃ©ricos\n",
    "    feat_names = np.array([f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "# Ordenar por importancia (de mayor a menor)\n",
    "order = np.argsort(importances)[::-1]\n",
    "\n",
    "# GRAFICAR\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=120)\n",
    "ax.bar(range(len(importances)), importances[order])\n",
    "ax.set_xticks(range(len(importances)))\n",
    "ax.set_xticklabels(feat_names[order], rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Importancia\")\n",
    "ax.set_title(\"Importancia de Variables â€” Ãrbol de DecisiÃ³n\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MOSTRAR TABLA\n",
    "print(\"\\nðŸ“Š Ranking de Importancia:\")\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': feat_names[order],\n",
    "    'Importancia': importances[order]\n",
    "})\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c057c4",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£2ï¸âƒ£ PASO 12: Visualizar el Ãrbol de DecisiÃ³n\n",
    "\n",
    "**Obligatorio:** âŒ NO - Pero excelente para entender cÃ³mo funciona el modelo.\n",
    "\n",
    "**ParÃ¡metros de plot_tree:**\n",
    "- **`filled=True`:** Colorea los nodos segÃºn la clase predominante\n",
    "- **`rounded=True`:** Bordes redondeados (mÃ¡s estÃ©tico)\n",
    "- **`impurity=True`:** Muestra el valor de Gini/Entropy en cada nodo\n",
    "- **`proportion=True`:** Muestra proporciones en lugar de conteos absolutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree as sktree\n",
    "\n",
    "# Obtener nombres de caracterÃ­sticas y clases\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_names = X.columns.tolist()\n",
    "else:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "class_names = [str(c) for c in np.unique(y)]\n",
    "\n",
    "# VISUALIZAR ÃRBOL\n",
    "fig, ax = plt.subplots(figsize=(14, 7), dpi=120)  # ðŸ“ MODIFICAR: Ajustar tamaÃ±o si es necesario\n",
    "\n",
    "sktree.plot_tree(\n",
    "    tree_optimized,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,          # Colorear nodos\n",
    "    rounded=True,         # Bordes redondeados\n",
    "    impurity=True,        # Mostrar Gini/Entropy\n",
    "    proportion=True       # Mostrar proporciones\n",
    ")\n",
    "ax.set_title(\"Ãrbol de DecisiÃ³n Optimizado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a3641",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£3ï¸âƒ£ PASO 13: Exportar Ãrbol como Imagen de Alta Calidad (Graphviz)\n",
    "\n",
    "**Obligatorio:** âŒ NO - Solo si quieres guardar una imagen del Ã¡rbol.\n",
    "\n",
    "**âš ï¸ REQUISITO:** Solo funciona en Google Colab o si tienes Graphviz instalado localmente.\n",
    "\n",
    "**Â¿CuÃ¡ndo usar?**\n",
    "- Si estÃ¡s en **Google Colab** â†’ âœ… Usar\n",
    "- Si estÃ¡s en **Jupyter local** â†’ Solo si instalaste Graphviz\n",
    "- Si no funciona â†’ Usa el mÃ©todo anterior (plot_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ SOLO EN GOOGLE COLAB - Instalar Graphviz\n",
    "# Descomentar las siguientes lÃ­neas si estÃ¡s en Colab:\n",
    "\n",
    "# !apt-get -qq install graphviz\n",
    "# !pip -q install graphviz pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTAR ÃRBOL CON GRAPHVIZ (versiÃ³n de alta calidad)\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Obtener nombres\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_names = X.columns.tolist()\n",
    "else:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "class_names = [str(c) for c in np.unique(y)]\n",
    "\n",
    "# GENERAR GRÃFICO\n",
    "dot = export_graphviz(\n",
    "    tree_optimized,\n",
    "    out_file=None,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    "    impurity=True,\n",
    "    proportion=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot)\n",
    "graph.format = \"png\"  # ðŸ“ MODIFICAR: \"png\", \"svg\", \"pdf\"\n",
    "graph.render(\"arbol_decision\", cleanup=True)  # Guarda como archivo\n",
    "\n",
    "# Mostrar en notebook\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5671241",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£4ï¸âƒ£ PASO 14: Curva de Aprendizaje\n",
    "\n",
    "**Obligatorio:** âŒ NO - Pero Ãºtil para diagnosticar sobreajuste/subajuste.\n",
    "\n",
    "**Â¿QuÃ© muestra?**\n",
    "- CÃ³mo cambia el rendimiento del modelo segÃºn el tamaÃ±o del conjunto de entrenamiento\n",
    "- **Brecha grande entre curvas:** Posible sobreajuste\n",
    "- **Ambas curvas bajas:** Posible subajuste\n",
    "\n",
    "**ParÃ¡metros:**\n",
    "- **`cv=5`:** NÃºmero de folds para validaciÃ³n cruzada (ðŸ“ comÃºn: 5 o 10)\n",
    "- **`scoring=\"f1_macro\"`:** MÃ©trica a evaluar (ðŸ“ opciones: \"accuracy\", \"f1\", \"precision\")\n",
    "- **`train_sizes`:** Proporciones del dataset a usar (ðŸ“ np.linspace(0.1, 1.0, 5) = 10%, 32%, 55%, 77%, 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e66277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# CALCULAR CURVA DE APRENDIZAJE\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    estimator=DecisionTreeClassifier(max_depth=4, random_state=42),\n",
    "    X=X, y=y,\n",
    "    cv=5,                    # ðŸ“ MODIFICAR: NÃºmero de folds\n",
    "    scoring=\"f1_macro\",      # ðŸ“ MODIFICAR: MÃ©trica a evaluar\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),  # ðŸ“ MODIFICAR: TamaÃ±os a probar\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CALCULAR MEDIAS\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "valid_mean = valid_scores.mean(axis=1)\n",
    "\n",
    "# GRAFICAR\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=120)\n",
    "ax.plot(train_sizes, train_mean, marker=\"o\", label=\"Entrenamiento\")\n",
    "ax.plot(train_sizes, valid_mean, marker=\"s\", label=\"ValidaciÃ³n (CV)\")\n",
    "ax.set_xlabel(\"TamaÃ±o del conjunto de entrenamiento\")\n",
    "ax.set_ylabel(\"F1 macro\")\n",
    "ax.set_title(\"Curva de Aprendizaje â€” Ãrbol de DecisiÃ³n\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55803cf",
   "metadata": {},
   "source": [
    "**ðŸ“– InterpretaciÃ³n:**\n",
    "- **Curvas muy separadas:** El modelo estÃ¡ sobreajustando (demasiado complejo)\n",
    "- **Curvas muy juntas pero bajas:** El modelo estÃ¡ subajustando (muy simple)\n",
    "- **Curvas juntas y altas:** Â¡Modelo bien balanceado! âœ…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b9726",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£5ï¸âƒ£ PASO 15: ComparaciÃ³n de Criterios (Experimento Manual)\n",
    "\n",
    "**Obligatorio:** âŒ NO - Solo para experimentaciÃ³n y aprendizaje.\n",
    "\n",
    "**Â¿QuÃ© hace?** Compara el rendimiento usando diferentes criterios de divisiÃ³n.\n",
    "\n",
    "**Ãštil para:** Entender el impacto de cada parÃ¡metro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86004462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAR DIFERENTES CRITERIOS\n",
    "criterios = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "resultados = []\n",
    "\n",
    "for c in criterios:\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion=c,\n",
    "        max_depth=4,  # ðŸ“ MODIFICAR: Profundidad fija para comparaciÃ³n justa\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    resultados.append((c, acc))\n",
    "\n",
    "# MOSTRAR RESULTADOS\n",
    "comparison_df = pd.DataFrame(resultados, columns=[\"criterion\", \"accuracy\"])\n",
    "comparison_df = comparison_df.sort_values(\"accuracy\", ascending=False)\n",
    "print(\"\\nðŸ“Š ComparaciÃ³n de Criterios:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537e71b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£6ï¸âƒ£ PASO 16: BÃºsqueda Exhaustiva Manual (Experimento Avanzado)\n",
    "\n",
    "**Obligatorio:** âŒ NO - Alternativa manual a GridSearchCV.\n",
    "\n",
    "**Â¿CuÃ¡ndo usar?** Si quieres ver TODAS las combinaciones de parÃ¡metros en una tabla.\n",
    "\n",
    "**ParÃ¡metros adicionales:**\n",
    "- **`min_samples_split`:** MÃ­nimo de muestras para dividir un nodo (ðŸ“ por defecto: 2)\n",
    "- **`min_samples_leaf`:** MÃ­nimo de muestras en cada hoja (ðŸ“ por defecto: 1)\n",
    "- **`max_features`:** MÃ¡ximo de caracterÃ­sticas a considerar (ðŸ“ None = todas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÃšSQUEDA MANUAL EXHAUSTIVA\n",
    "criterios = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "profundidades = [3, 4, 5, 6, 8, None]  # ðŸ“ MODIFICAR: Profundidades a probar\n",
    "resultados = []\n",
    "\n",
    "print(\"â³ Probando combinaciones...\")\n",
    "for c in criterios:\n",
    "    for depth in profundidades:\n",
    "        clf = DecisionTreeClassifier(\n",
    "            criterion=c,\n",
    "            max_depth=depth,\n",
    "            min_samples_split=2,   # ðŸ“ MODIFICAR: Ajustar segÃºn necesidad\n",
    "            min_samples_leaf=1,    # ðŸ“ MODIFICAR: Ajustar segÃºn necesidad\n",
    "            max_features=None,     # ðŸ“ MODIFICAR: None, \"sqrt\", \"log2\"\n",
    "            random_state=42\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        resultados.append((c, depth, acc))\n",
    "\n",
    "# CREAR TABLA DE RESULTADOS\n",
    "results_df = pd.DataFrame(resultados, columns=[\"criterion\", \"max_depth\", \"accuracy\"])\n",
    "results_df = results_df.sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\nâœ… Resultados completos (ordenados por accuracy):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nðŸ† Mejor combinaciÃ³n: {results_df.iloc[0]['criterion']} + max_depth={results_df.iloc[0]['max_depth']} â†’ {results_df.iloc[0]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f889bcb",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£7ï¸âƒ£ PASO 17: GridSearchCV con MÃ¡s ParÃ¡metros (BÃºsqueda Avanzada)\n",
    "\n",
    "**Obligatorio:** âŒ NO - VersiÃ³n mÃ¡s completa de GridSearch.\n",
    "\n",
    "**âš ï¸ ADVERTENCIA:** Probar muchos parÃ¡metros puede ser MUY LENTO.\n",
    "\n",
    "**ParÃ¡metros adicionales explicados:**\n",
    "\n",
    "### ðŸ”§ `min_samples_split`\n",
    "- MÃ­nimo de muestras necesarias para dividir un nodo interno\n",
    "- **Valores tÃ­picos:** 2 (por defecto), 5, 10, 20\n",
    "- **Mayor valor:** Menos divisiones, Ã¡rbol mÃ¡s simple\n",
    "\n",
    "### ðŸ”§ `min_samples_leaf`\n",
    "- MÃ­nimo de muestras necesarias en cada nodo hoja\n",
    "- **Valores tÃ­picos:** 1 (por defecto), 2, 5, 10\n",
    "- **Mayor valor:** Hojas mÃ¡s \"gruesas\", reduce sobreajuste\n",
    "\n",
    "### ðŸ”§ `max_features`\n",
    "- NÃºmero mÃ¡ximo de caracterÃ­sticas a considerar para cada divisiÃ³n\n",
    "- **Opciones:** None (todas), \"sqrt\" (raÃ­z cuadrada), \"log2\" (logaritmo base 2)\n",
    "- **Ãštil para:** Reducir correlaciÃ³n entre Ã¡rboles en Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH CON MUCHOS PARÃMETROS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    # Descomentar para bÃºsqueda mÃ¡s exhaustiva (Â¡mÃ¡s lento!):\n",
    "    # \"min_samples_split\": [2, 5, 10],\n",
    "    # \"min_samples_leaf\": [1, 2, 5],\n",
    "    # \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",  # ðŸ“ MODIFICAR: \"accuracy\", \"f1\", \"roc_auc\"\n",
    "    cv=5,                # ðŸ“ MODIFICAR: NÃºmero de folds\n",
    "    n_jobs=-1,\n",
    "    verbose=1            # Mostrar progreso\n",
    ")\n",
    "\n",
    "print(\"â³ Ejecutando bÃºsqueda exhaustiva...\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ… BÃºsqueda completada\")\n",
    "print(f\"\\nðŸ† Mejores parÃ¡metros: {grid.best_params_}\")\n",
    "print(f\"ðŸ“Š Mejor accuracy (CV): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcb205",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£8ï¸âƒ£ PASO 18: Modelo Final Definitivo\n",
    "\n",
    "**Obligatorio:** âœ… SÃ - Entrenar el modelo final con los mejores parÃ¡metros encontrados.\n",
    "\n",
    "**ðŸ“ IMPORTANTE:** Actualiza los parÃ¡metros con los valores de `grid.best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO FINAL CON LOS MEJORES PARÃMETROS\n",
    "# ðŸ“ MODIFICAR: Usa los valores que obtuviste del GridSearch anterior\n",
    "\n",
    "clf_final = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",    # ðŸ“ Actualizar segÃºn best_params_\n",
    "    max_depth=8,         # ðŸ“ Actualizar segÃºn best_params_\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# EVALUAR\n",
    "acc_final = clf_final.score(X_test, y_test)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ðŸŽ¯ MODELO FINAL - RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy en test: {acc_final:.4f} ({acc_final*100:.2f}%)\")\n",
    "print(f\"Profundidad del Ã¡rbol: {clf_final.get_depth()}\")\n",
    "print(f\"NÃºmero de hojas: {clf_final.get_n_leaves()}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16222c5",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ“ RESUMEN Y GUÃA RÃPIDA\n",
    "\n",
    "### âœ… Pasos OBLIGATORIOS (flujo mÃ­nimo):\n",
    "1. Importar librerÃ­as\n",
    "2. Cargar datos\n",
    "3. Dividir datos (train/test)\n",
    "4. Crear y entrenar modelo\n",
    "5. Evaluar modelo\n",
    "\n",
    "### âš ï¸ Pasos OPCIONALES pero RECOMENDADOS:\n",
    "- GridSearchCV (optimizaciÃ³n de parÃ¡metros)\n",
    "- Matriz de confusiÃ³n y mÃ©tricas\n",
    "- VisualizaciÃ³n del Ã¡rbol\n",
    "- Importancia de variables\n",
    "\n",
    "### âŒ Pasos OPCIONALES segÃºn dataset:\n",
    "- Variables dummy (solo si tienes categÃ³ricas)\n",
    "- Escalado (no necesario para Ã¡rboles)\n",
    "- Graphviz (solo en Colab o con instalaciÃ³n local)\n",
    "\n",
    "### ðŸ”§ ParÃ¡metros principales para experimentar:\n",
    "\n",
    "| ParÃ¡metro | Valores tÃ­picos | Efecto |\n",
    "|-----------|----------------|--------|\n",
    "| `criterion` | \"gini\", \"entropy\" | MÃ©todo de divisiÃ³n |\n",
    "| `max_depth` | 3-10, None | Profundidad del Ã¡rbol |\n",
    "| `min_samples_split` | 2, 5, 10 | Control de divisiones |\n",
    "| `min_samples_leaf` | 1, 2, 5 | TamaÃ±o mÃ­nimo de hojas |\n",
    "| `test_size` | 0.20-0.30 | ProporciÃ³n de datos test |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’¡ CONSEJOS PARA MODIFICAR Y EXPERIMENTAR:\n",
    "\n",
    "1. **Para un nuevo dataset:**\n",
    "   - Cambia el nombre del archivo CSV en el Paso 2\n",
    "   - Cambia el nombre de la columna objetivo\n",
    "   - Verifica si tienes variables categÃ³ricas (Paso 3)\n",
    "\n",
    "2. **Para mejorar el modelo:**\n",
    "   - Ejecuta GridSearchCV (Paso 7 o 17)\n",
    "   - Usa los mejores parÃ¡metros encontrados\n",
    "   - Prueba con diferentes mÃ©tricas (accuracy, f1, precision)\n",
    "\n",
    "3. **Para datasets pequeÃ±os (<1000 filas):**\n",
    "   - Aumenta `test_size` a 0.30-0.40\n",
    "   - Usa CV mÃ¡s alto (cv=10 en GridSearch)\n",
    "   - Limita `max_depth` a 3-5 para evitar sobreajuste\n",
    "\n",
    "4. **Para datasets grandes (>10000 filas):**\n",
    "   - Reduce `test_size` a 0.10-0.20\n",
    "   - Puedes probar Ã¡rboles mÃ¡s profundos\n",
    "   - Usa `n_jobs=-1` para paralelizar\n",
    "\n",
    "---\n",
    "\n",
    "**Â¡Listo para experimentar! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
