{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badc685b",
   "metadata": {},
   "source": [
    "# 🌳 Tutorial Completo: Árbol de Decisión para Clasificación\n",
    "\n",
    "Este notebook contiene un flujo completo de Machine Learning usando **Árboles de Decisión** para clasificación binaria.\n",
    "\n",
    "## 📋 Contenido:\n",
    "1. Importación de librerías\n",
    "2. Carga y preparación de datos\n",
    "3. Preprocesamiento (opcional según tu dataset)\n",
    "4. División de datos\n",
    "5. Entrenamiento del modelo\n",
    "6. Optimización de hiperparámetros\n",
    "7. Evaluación y visualizaciones\n",
    "8. Análisis avanzado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b44a1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣ PASO 1: Importar Librerías Necesarias\n",
    "\n",
    "**¿Qué hace?** Importa todas las librerías que usaremos durante el análisis.\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Siempre necesario al inicio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías básicas para manejo de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Librerías de scikit-learn para el modelo y división de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Librerías para evaluación y métricas\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, RocCurveDisplay,\n",
    "                             PrecisionRecallDisplay, classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33d7182",
   "metadata": {},
   "source": [
    "---\n",
    "## 2️⃣ PASO 2: Cargar y Preparar el Dataset\n",
    "\n",
    "**¿Qué hace?** \n",
    "- Lee el archivo CSV con los datos\n",
    "- Separa las **variables independientes (X)** de la **variable objetivo (y)**\n",
    "\n",
    "**Parámetros a modificar:**\n",
    "- `\"diabetes.csv\"` → Cambia esto por el nombre de tu archivo\n",
    "- `\"Outcome\"` → Cambia esto por el nombre de tu columna objetivo\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Necesitas cargar tus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d56e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEER ARCHIVO CSV\n",
    "# 📝 MODIFICAR: Cambia \"diabetes.csv\" por el nombre de tu archivo\n",
    "df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# IDENTIFICAR COLUMNA OBJETIVO (la que queremos predecir)\n",
    "# 📝 MODIFICAR: Cambia \"Outcome\" por el nombre de tu columna objetivo\n",
    "y = df[\"Outcome\"]  # Variable dependiente (lo que queremos predecir)\n",
    "\n",
    "# ELIMINAR COLUMNA OBJETIVO del conjunto de características\n",
    "X = df.drop(columns=[\"Outcome\"])  # Variables independientes (features)\n",
    "\n",
    "# MOSTRAR LA SEPARACIÓN para verificar\n",
    "display(y.head())  # Primeros valores de la variable objetivo\n",
    "display(X.head())  # Primeras filas de las características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4dac0",
   "metadata": {},
   "source": [
    "### 📌 MÉTODO ALTERNATIVO: Selección por Índices\n",
    "\n",
    "**Obligatorio:** ❌ NO - Solo si prefieres seleccionar columnas por posición en lugar de por nombre.\n",
    "\n",
    "**¿Cuándo usar?** Si no tienes nombres de columnas o prefieres trabajar con índices numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b715be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTRA FORMA DE OBTENER VARIABLES (usando índices)\n",
    "# X = df.iloc[:, 0:8].values   # Toma columnas 0 a 7 (todas las características)\n",
    "# y = df.iloc[:, -1].values     # Toma la última columna (objetivo)\n",
    "\n",
    "# 📝 MODIFICAR:\n",
    "# - 0:8 → Cambia por el rango de tus columnas de características\n",
    "# - -1 → Mantener si tu objetivo está en la última columna, sino cambia el índice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d7567b",
   "metadata": {},
   "source": [
    "---\n",
    "## 3️⃣ PASO 3: Codificación de Variables Categóricas (Variables Dummies)\n",
    "\n",
    "**Obligatorio:** ❌ NO - **SOLO si tienes variables categóricas (texto) en tu dataset**\n",
    "\n",
    "**¿Cuándo usar?**\n",
    "- Si tienes columnas con valores como: \"Masculino/Femenino\", \"Alto/Medio/Bajo\", etc.\n",
    "- Si todas tus columnas ya son numéricas, **SALTA ESTA CELDA**\n",
    "\n",
    "**⚠️ ADVERTENCIA:** El código actual tiene errores. Aquí está la versión corregida.\n",
    "\n",
    "**Parámetros:**\n",
    "- `[3]` → Índice de la columna categórica a convertir (cambia según tu dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb58470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ ESTA CELDA ES OPCIONAL - Solo si tienes variables categóricas\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Supongamos que la columna 3 es categórica (ej: \"Alto\", \"Medio\", \"Bajo\")\n",
    "# 📝 MODIFICAR: Cambia [3] por el índice de tu columna categórica\n",
    "\n",
    "# Convertir X a numpy array si es DataFrame\n",
    "X_array = X.values\n",
    "\n",
    "# Codificar la columna categórica a números\n",
    "labelencoder_X = LabelEncoder()\n",
    "X_array[:, 3] = labelencoder_X.fit_transform(X_array[:, 3])\n",
    "\n",
    "# Aplicar One-Hot Encoding (crear variables dummy)\n",
    "onehotencoder = make_column_transformer(\n",
    "    (OneHotEncoder(), [3]),  # Columna a codificar\n",
    "    remainder=\"passthrough\"  # Mantener las demás columnas sin cambios\n",
    ")\n",
    "X = onehotencoder.fit_transform(X_array)\n",
    "\n",
    "# ELIMINAR la primera columna dummy para evitar multicolinealidad (Dummy Variable Trap)\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ba77f",
   "metadata": {},
   "source": [
    "---\n",
    "## 4️⃣ PASO 4: Escalado de Variables (Normalización/Estandarización)\n",
    "\n",
    "**Obligatorio:** ⚠️ DEPENDE\n",
    "\n",
    "**¿Cuándo usar?**\n",
    "- **SÍ necesario** para: SVM, KNN, Regresión Logística, Redes Neuronales\n",
    "- **NO necesario** para: Árboles de Decisión, Random Forest, XGBoost\n",
    "\n",
    "Para **Árboles de Decisión** (nuestro caso) puedes **SALTAR** esta celda, pero no hace daño aplicarlo.\n",
    "\n",
    "**¿Qué hace?** Escala las variables para que tengan media 0 y desviación estándar 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dca498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ ESTA CELDA ES OPCIONAL para Árboles de Decisión\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Verificar el resultado\n",
    "print(\"Datos escalados (primeras 5 filas):\")\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0184d141",
   "metadata": {},
   "source": [
    "---\n",
    "## 5️⃣ PASO 5: Dividir los Datos en Entrenamiento y Prueba\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Fundamental para evaluar el modelo correctamente.\n",
    "\n",
    "**Parámetros importantes:**\n",
    "\n",
    "### 🔧 `test_size` (Tamaño del conjunto de prueba)\n",
    "- **Valor:** 0.25 (25% prueba, 75% entrenamiento)\n",
    "- **Recomendaciones según tamaño del dataset:**\n",
    "  - Dataset GRANDE (>10,000 filas): `0.10` a `0.20` (10-20%)\n",
    "  - Dataset MEDIANO (1,000-10,000): `0.20` a `0.30` (20-30%)\n",
    "  - Dataset PEQUEÑO (<1,000): `0.30` a `0.40` (30-40%)\n",
    "\n",
    "### 🔧 `random_state`\n",
    "- **Valor:** 42 (puede ser cualquier número)\n",
    "- **Propósito:** Hace que la división sea reproducible (siempre igual)\n",
    "\n",
    "### 🔧 `stratify`\n",
    "- **Valor:** `y` (la variable objetivo)\n",
    "- **Propósito:** Mantiene la misma proporción de clases en entrenamiento y prueba\n",
    "- **Ejemplo:** Si tienes 60% clase 0 y 40% clase 1, ambos conjuntos tendrán esa proporción\n",
    "\n",
    "### 🔧 `shuffle` (no usado aquí, pero disponible)\n",
    "- **Valor por defecto:** `True`\n",
    "- **Propósito:** Mezcla los datos antes de dividir\n",
    "- **Cuándo usar False:** Solo si tus datos tienen orden temporal importante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38232b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDIR LA DATA en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,      # 📝 MODIFICAR: 25% para prueba, 75% para entrenar\n",
    "    random_state=42,     # 📝 MODIFICAR: Cualquier número para reproducibilidad\n",
    "    stratify=y           # Mantiene proporciones de clases balanceadas\n",
    ")\n",
    "\n",
    "print(f\"Datos de entrenamiento: {X_train.shape[0]} filas\")\n",
    "print(f\"Datos de prueba: {X_test.shape[0]} filas\")\n",
    "print(f\"\\nDistribución de clases en entrenamiento:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nDistribución de clases en prueba:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aa14d1",
   "metadata": {},
   "source": [
    "---\n",
    "## 6️⃣ PASO 6: Crear y Entrenar el Modelo (Versión Básica)\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Este es el corazón del análisis.\n",
    "\n",
    "**Parámetros del DecisionTreeClassifier:**\n",
    "\n",
    "### 🔧 `criterion` (Criterio de división)\n",
    "- **Opciones:** `\"gini\"`, `\"entropy\"`, `\"log_loss\"`\n",
    "- **Por defecto:** `\"gini\"`\n",
    "- **Gini:** Más rápido, usado comúnmente\n",
    "- **Entropy:** Basado en teoría de información, puede ser más preciso\n",
    "- **Log_loss:** Similar a entropy, útil en algunos casos\n",
    "\n",
    "### 🔧 `max_depth` (Profundidad máxima del árbol)\n",
    "- **Opciones:** Cualquier entero positivo o `None`\n",
    "- **Por defecto:** `None` (sin límite)\n",
    "- **Recomendado:** 3-10 para evitar sobreajuste\n",
    "- **Menor profundidad:** Modelo más simple, menos sobreajuste\n",
    "- **Mayor profundidad:** Modelo más complejo, puede sobreajustar\n",
    "\n",
    "### 🔧 `random_state` (Semilla aleatoria)\n",
    "- **Valor:** Cualquier entero\n",
    "- **Propósito:** Reproducibilidad de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c631f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR EL MODELO DE ÁRBOL DE DECISIÓN (versión básica con parámetros por defecto)\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# Parámetros opcionales que puedes agregar:\n",
    "# criterion=\"gini\",        # 📝 MODIFICAR: \"gini\", \"entropy\", o \"log_loss\"\n",
    "# max_depth=4,             # 📝 MODIFICAR: Número entre 2-10, o None para sin límite\n",
    "# random_state=42          # 📝 MODIFICAR: Para reproducibilidad\n",
    "\n",
    "print(\"Modelo creado con parámetros por defecto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTRENAR EL MODELO con los datos de entrenamiento\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Modelo entrenado exitosamente\")\n",
    "print(f\"Profundidad del árbol: {tree.get_depth()}\")\n",
    "print(f\"Número de hojas: {tree.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HACER PREDICCIONES con los datos de prueba\n",
    "y_pred = tree.predict(X_test)\n",
    "\n",
    "print(\"Predicciones realizadas:\")\n",
    "print(y_pred[:10])  # Mostrar las primeras 10 predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUAR LA PRECISIÓN del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"📊 Precisión del modelo: {accuracy:.4f} ({accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba8d0ae",
   "metadata": {},
   "source": [
    "---\n",
    "## 7️⃣ PASO 7: Optimización de Hiperparámetros con GridSearchCV\n",
    "\n",
    "**Obligatorio:** ❌ NO - Pero **MUY RECOMENDADO** para mejorar el rendimiento.\n",
    "\n",
    "**¿Qué hace?** Prueba todas las combinaciones de parámetros para encontrar la mejor.\n",
    "\n",
    "**Parámetros de GridSearchCV:**\n",
    "\n",
    "### 🔧 `param_grid` (Diccionario de parámetros a probar)\n",
    "- Define qué valores probar para cada parámetro\n",
    "- **Más opciones = Más tiempo de ejecución**\n",
    "\n",
    "### 🔧 `cv` (Cross-validation)\n",
    "- **Valor:** Número de \"folds\" (divisiones)\n",
    "- **Común:** 5 o 10\n",
    "- **Mayor valor:** Más preciso pero más lento\n",
    "\n",
    "### 🔧 `n_jobs`\n",
    "- **Valor:** -1 (usar todos los procesadores)\n",
    "- **Propósito:** Acelerar el proceso usando paralelización\n",
    "\n",
    "### 🔧 `scoring`\n",
    "- **Opciones:** \"accuracy\", \"f1\", \"precision\", \"recall\", \"roc_auc\"\n",
    "- **Por defecto:** \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINIR PARÁMETROS A PROBAR\n",
    "param_dist = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],  # 📝 MODIFICAR: Criterios a probar\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, 9, None],  # 📝 MODIFICAR: Profundidades a probar\n",
    "}\n",
    "\n",
    "# NOTA: Puedes agregar más parámetros:\n",
    "# \"min_samples_split\": [2, 5, 10],      # Mínimo de muestras para dividir un nodo\n",
    "# \"min_samples_leaf\": [1, 2, 5],        # Mínimo de muestras en cada hoja\n",
    "# \"max_features\": [None, \"sqrt\", \"log2\"] # Número máximo de características a considerar\n",
    "\n",
    "print(f\"Se probarán {len(param_dist['criterion']) * len(param_dist['max_depth'])} combinaciones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d5dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR Y EJECUTAR GRID SEARCH\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    tree,\n",
    "    param_grid=param_dist,\n",
    "    cv=15,              # 📝 MODIFICAR: Número de folds (común: 5 o 10)\n",
    "    n_jobs=-1,          # Usar todos los procesadores disponibles\n",
    "    scoring=\"accuracy\"  # 📝 MODIFICAR: Métrica a optimizar\n",
    ")\n",
    "\n",
    "print(\"⏳ Buscando mejores parámetros... (esto puede tardar)\")\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"✅ Búsqueda completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c977795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER EL MEJOR ESTIMADOR ENCONTRADO\n",
    "print(\"🏆 Mejor modelo encontrado:\")\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER EL MEJOR SCORE (precisión)\n",
    "print(f\"📊 Mejor score (accuracy): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VER LOS MEJORES PARÁMETROS\n",
    "print(\"⚙️ Mejores parámetros encontrados:\")\n",
    "for param, value in grid.best_params_.items():\n",
    "    print(f\"  • {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db61dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 8️⃣ PASO 8: Entrenar Modelo Final con Mejores Parámetros\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Si hiciste GridSearch, usa los mejores parámetros encontrados.\n",
    "\n",
    "**¿Qué hace?** Crea un nuevo modelo con los parámetros óptimos y lo evalúa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd94639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREAR MODELO CON LOS MEJORES PARÁMETROS\n",
    "# 📝 MODIFICAR: Usa los valores que obteniste de grid.best_params_\n",
    "\n",
    "tree_optimized = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",    # 📝 Usar el valor de best_params_\n",
    "    max_depth=8,         # 📝 Usar el valor de best_params_\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "tree_optimized.fit(X_train, y_train)\n",
    "\n",
    "# PREDECIR\n",
    "y_pred_optimized = tree_optimized.predict(X_test)\n",
    "\n",
    "# EVALUAR\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"📊 Precisión del modelo optimizado: {accuracy_optimized:.4f} ({accuracy_optimized*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706e024",
   "metadata": {},
   "source": [
    "---\n",
    "## 9️⃣ PASO 9: Visualización de Métricas - Matriz de Confusión\n",
    "\n",
    "**Obligatorio:** ⚠️ RECOMENDADO - Esencial para entender el rendimiento del modelo.\n",
    "\n",
    "**¿Qué muestra?**\n",
    "- **Verdaderos Positivos (VP):** Predicciones correctas de clase 1\n",
    "- **Verdaderos Negativos (VN):** Predicciones correctas de clase 0\n",
    "- **Falsos Positivos (FP):** Predicciones incorrectas como clase 1\n",
    "- **Falsos Negativos (FN):** Predicciones incorrectas como clase 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559dd1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MATRIZ DE CONFUSIÓN\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    tree_optimized,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    ax=ax,\n",
    "    cmap=\"Blues\"  # 📝 MODIFICAR: Color (\"Blues\", \"Greens\", \"Reds\", \"Purples\")\n",
    ")\n",
    "ax.set_title(\"Matriz de Confusión — Árbol de Decisión Optimizado\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# REPORTE DE CLASIFICACIÓN (métricas detalladas)\n",
    "print(\"\\n📋 Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred_optimized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc35f06",
   "metadata": {},
   "source": [
    "**📖 Interpretación del Reporte:**\n",
    "- **Precision:** De todas las predicciones positivas, ¿cuántas fueron correctas?\n",
    "- **Recall (Sensibilidad):** De todos los positivos reales, ¿cuántos detectamos?\n",
    "- **F1-Score:** Media armónica de Precision y Recall\n",
    "- **Support:** Número de muestras de cada clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f9fb9",
   "metadata": {},
   "source": [
    "---\n",
    "## 🔟 PASO 10: Curvas ROC y Precision-Recall\n",
    "\n",
    "**Obligatorio:** ⚠️ RECOMENDADO - Muy útil para evaluar modelos de clasificación.\n",
    "\n",
    "**Curva ROC:**\n",
    "- Muestra la relación entre Tasa de Verdaderos Positivos vs Falsos Positivos\n",
    "- **AUC (Area Under Curve):** Métrica resumen (0.5 = aleatorio, 1.0 = perfecto)\n",
    "\n",
    "**Curva Precision-Recall:**\n",
    "- Útil cuando las clases están desbalanceadas\n",
    "- Muestra el balance entre Precision y Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840bbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CURVA ROC\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "RocCurveDisplay.from_estimator(tree_optimized, X_test, y_test, ax=ax)\n",
    "ax.set_title(\"Curva ROC\")\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio')  # Línea diagonal\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# CURVA PRECISION-RECALL\n",
    "fig, ax = plt.subplots(figsize=(5, 4), dpi=120)\n",
    "PrecisionRecallDisplay.from_estimator(tree_optimized, X_test, y_test, ax=ax)\n",
    "ax.set_title(\"Curva Precision–Recall\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86a62b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣1️⃣ PASO 11: Importancia de Variables\n",
    "\n",
    "**Obligatorio:** ❌ NO - Pero muy útil para interpretar el modelo.\n",
    "\n",
    "**¿Qué muestra?** Qué características (variables) son más importantes para las predicciones del árbol.\n",
    "\n",
    "**⚠️ NOTA:** Esta celda requiere que `X` sea un DataFrame con nombres de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f474d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANCIA DE VARIABLES\n",
    "importances = tree_optimized.feature_importances_\n",
    "\n",
    "# Obtener nombres de características (ajustar según tu caso)\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feat_names = X.columns.to_numpy()\n",
    "else:\n",
    "    # Si X no es DataFrame, crear nombres genéricos\n",
    "    feat_names = np.array([f\"Feature_{i}\" for i in range(X.shape[1])])\n",
    "\n",
    "# Ordenar por importancia (de mayor a menor)\n",
    "order = np.argsort(importances)[::-1]\n",
    "\n",
    "# GRAFICAR\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=120)\n",
    "ax.bar(range(len(importances)), importances[order])\n",
    "ax.set_xticks(range(len(importances)))\n",
    "ax.set_xticklabels(feat_names[order], rotation=45, ha=\"right\")\n",
    "ax.set_ylabel(\"Importancia\")\n",
    "ax.set_title(\"Importancia de Variables — Árbol de Decisión\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# MOSTRAR TABLA\n",
    "print(\"\\n📊 Ranking de Importancia:\")\n",
    "importance_df = pd.DataFrame({\n",
    "    'Variable': feat_names[order],\n",
    "    'Importancia': importances[order]\n",
    "})\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c057c4",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣2️⃣ PASO 12: Visualizar el Árbol de Decisión\n",
    "\n",
    "**Obligatorio:** ❌ NO - Pero excelente para entender cómo funciona el modelo.\n",
    "\n",
    "**Parámetros de plot_tree:**\n",
    "- **`filled=True`:** Colorea los nodos según la clase predominante\n",
    "- **`rounded=True`:** Bordes redondeados (más estético)\n",
    "- **`impurity=True`:** Muestra el valor de Gini/Entropy en cada nodo\n",
    "- **`proportion=True`:** Muestra proporciones en lugar de conteos absolutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree as sktree\n",
    "\n",
    "# Obtener nombres de características y clases\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_names = X.columns.tolist()\n",
    "else:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "class_names = [str(c) for c in np.unique(y)]\n",
    "\n",
    "# VISUALIZAR ÁRBOL\n",
    "fig, ax = plt.subplots(figsize=(14, 7), dpi=120)  # 📝 MODIFICAR: Ajustar tamaño si es necesario\n",
    "\n",
    "sktree.plot_tree(\n",
    "    tree_optimized,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,          # Colorear nodos\n",
    "    rounded=True,         # Bordes redondeados\n",
    "    impurity=True,        # Mostrar Gini/Entropy\n",
    "    proportion=True       # Mostrar proporciones\n",
    ")\n",
    "ax.set_title(\"Árbol de Decisión Optimizado\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13a3641",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣3️⃣ PASO 13: Exportar Árbol como Imagen de Alta Calidad (Graphviz)\n",
    "\n",
    "**Obligatorio:** ❌ NO - Solo si quieres guardar una imagen del árbol.\n",
    "\n",
    "**⚠️ REQUISITO:** Solo funciona en Google Colab o si tienes Graphviz instalado localmente.\n",
    "\n",
    "**¿Cuándo usar?**\n",
    "- Si estás en **Google Colab** → ✅ Usar\n",
    "- Si estás en **Jupyter local** → Solo si instalaste Graphviz\n",
    "- Si no funciona → Usa el método anterior (plot_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace4ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⚠️ SOLO EN GOOGLE COLAB - Instalar Graphviz\n",
    "# Descomentar las siguientes líneas si estás en Colab:\n",
    "\n",
    "# !apt-get -qq install graphviz\n",
    "# !pip -q install graphviz pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORTAR ÁRBOL CON GRAPHVIZ (versión de alta calidad)\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Obtener nombres\n",
    "if isinstance(X, pd.DataFrame):\n",
    "    feature_names = X.columns.tolist()\n",
    "else:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "class_names = [str(c) for c in np.unique(y)]\n",
    "\n",
    "# GENERAR GRÁFICO\n",
    "dot = export_graphviz(\n",
    "    tree_optimized,\n",
    "    out_file=None,\n",
    "    feature_names=feature_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    special_characters=True,\n",
    "    impurity=True,\n",
    "    proportion=True\n",
    ")\n",
    "\n",
    "graph = graphviz.Source(dot)\n",
    "graph.format = \"png\"  # 📝 MODIFICAR: \"png\", \"svg\", \"pdf\"\n",
    "graph.render(\"arbol_decision\", cleanup=True)  # Guarda como archivo\n",
    "\n",
    "# Mostrar en notebook\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5671241",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣4️⃣ PASO 14: Curva de Aprendizaje\n",
    "\n",
    "**Obligatorio:** ❌ NO - Pero útil para diagnosticar sobreajuste/subajuste.\n",
    "\n",
    "**¿Qué muestra?**\n",
    "- Cómo cambia el rendimiento del modelo según el tamaño del conjunto de entrenamiento\n",
    "- **Brecha grande entre curvas:** Posible sobreajuste\n",
    "- **Ambas curvas bajas:** Posible subajuste\n",
    "\n",
    "**Parámetros:**\n",
    "- **`cv=5`:** Número de folds para validación cruzada (📝 común: 5 o 10)\n",
    "- **`scoring=\"f1_macro\"`:** Métrica a evaluar (📝 opciones: \"accuracy\", \"f1\", \"precision\")\n",
    "- **`train_sizes`:** Proporciones del dataset a usar (📝 np.linspace(0.1, 1.0, 5) = 10%, 32%, 55%, 77%, 100%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e66277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# CALCULAR CURVA DE APRENDIZAJE\n",
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    estimator=DecisionTreeClassifier(max_depth=4, random_state=42),\n",
    "    X=X, y=y,\n",
    "    cv=5,                    # 📝 MODIFICAR: Número de folds\n",
    "    scoring=\"f1_macro\",      # 📝 MODIFICAR: Métrica a evaluar\n",
    "    n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),  # 📝 MODIFICAR: Tamaños a probar\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# CALCULAR MEDIAS\n",
    "train_mean = train_scores.mean(axis=1)\n",
    "valid_mean = valid_scores.mean(axis=1)\n",
    "\n",
    "# GRAFICAR\n",
    "fig, ax = plt.subplots(figsize=(6, 4), dpi=120)\n",
    "ax.plot(train_sizes, train_mean, marker=\"o\", label=\"Entrenamiento\")\n",
    "ax.plot(train_sizes, valid_mean, marker=\"s\", label=\"Validación (CV)\")\n",
    "ax.set_xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "ax.set_ylabel(\"F1 macro\")\n",
    "ax.set_title(\"Curva de Aprendizaje — Árbol de Decisión\")\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55803cf",
   "metadata": {},
   "source": [
    "**📖 Interpretación:**\n",
    "- **Curvas muy separadas:** El modelo está sobreajustando (demasiado complejo)\n",
    "- **Curvas muy juntas pero bajas:** El modelo está subajustando (muy simple)\n",
    "- **Curvas juntas y altas:** ¡Modelo bien balanceado! ✅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b9726",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣5️⃣ PASO 15: Comparación de Criterios (Experimento Manual)\n",
    "\n",
    "**Obligatorio:** ❌ NO - Solo para experimentación y aprendizaje.\n",
    "\n",
    "**¿Qué hace?** Compara el rendimiento usando diferentes criterios de división.\n",
    "\n",
    "**Útil para:** Entender el impacto de cada parámetro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86004462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPARAR DIFERENTES CRITERIOS\n",
    "criterios = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "resultados = []\n",
    "\n",
    "for c in criterios:\n",
    "    clf = DecisionTreeClassifier(\n",
    "        criterion=c,\n",
    "        max_depth=4,  # 📝 MODIFICAR: Profundidad fija para comparación justa\n",
    "        random_state=42\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    resultados.append((c, acc))\n",
    "\n",
    "# MOSTRAR RESULTADOS\n",
    "comparison_df = pd.DataFrame(resultados, columns=[\"criterion\", \"accuracy\"])\n",
    "comparison_df = comparison_df.sort_values(\"accuracy\", ascending=False)\n",
    "print(\"\\n📊 Comparación de Criterios:\")\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537e71b",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣6️⃣ PASO 16: Búsqueda Exhaustiva Manual (Experimento Avanzado)\n",
    "\n",
    "**Obligatorio:** ❌ NO - Alternativa manual a GridSearchCV.\n",
    "\n",
    "**¿Cuándo usar?** Si quieres ver TODAS las combinaciones de parámetros en una tabla.\n",
    "\n",
    "**Parámetros adicionales:**\n",
    "- **`min_samples_split`:** Mínimo de muestras para dividir un nodo (📝 por defecto: 2)\n",
    "- **`min_samples_leaf`:** Mínimo de muestras en cada hoja (📝 por defecto: 1)\n",
    "- **`max_features`:** Máximo de características a considerar (📝 None = todas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BÚSQUEDA MANUAL EXHAUSTIVA\n",
    "criterios = [\"gini\", \"entropy\", \"log_loss\"]\n",
    "profundidades = [3, 4, 5, 6, 8, None]  # 📝 MODIFICAR: Profundidades a probar\n",
    "resultados = []\n",
    "\n",
    "print(\"⏳ Probando combinaciones...\")\n",
    "for c in criterios:\n",
    "    for depth in profundidades:\n",
    "        clf = DecisionTreeClassifier(\n",
    "            criterion=c,\n",
    "            max_depth=depth,\n",
    "            min_samples_split=2,   # 📝 MODIFICAR: Ajustar según necesidad\n",
    "            min_samples_leaf=1,    # 📝 MODIFICAR: Ajustar según necesidad\n",
    "            max_features=None,     # 📝 MODIFICAR: None, \"sqrt\", \"log2\"\n",
    "            random_state=42\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        resultados.append((c, depth, acc))\n",
    "\n",
    "# CREAR TABLA DE RESULTADOS\n",
    "results_df = pd.DataFrame(resultados, columns=[\"criterion\", \"max_depth\", \"accuracy\"])\n",
    "results_df = results_df.sort_values(\"accuracy\", ascending=False)\n",
    "\n",
    "print(\"\\n✅ Resultados completos (ordenados por accuracy):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n🏆 Mejor combinación: {results_df.iloc[0]['criterion']} + max_depth={results_df.iloc[0]['max_depth']} → {results_df.iloc[0]['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f889bcb",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣7️⃣ PASO 17: GridSearchCV con Más Parámetros (Búsqueda Avanzada)\n",
    "\n",
    "**Obligatorio:** ❌ NO - Versión más completa de GridSearch.\n",
    "\n",
    "**⚠️ ADVERTENCIA:** Probar muchos parámetros puede ser MUY LENTO.\n",
    "\n",
    "**Parámetros adicionales explicados:**\n",
    "\n",
    "### 🔧 `min_samples_split`\n",
    "- Mínimo de muestras necesarias para dividir un nodo interno\n",
    "- **Valores típicos:** 2 (por defecto), 5, 10, 20\n",
    "- **Mayor valor:** Menos divisiones, árbol más simple\n",
    "\n",
    "### 🔧 `min_samples_leaf`\n",
    "- Mínimo de muestras necesarias en cada nodo hoja\n",
    "- **Valores típicos:** 1 (por defecto), 2, 5, 10\n",
    "- **Mayor valor:** Hojas más \"gruesas\", reduce sobreajuste\n",
    "\n",
    "### 🔧 `max_features`\n",
    "- Número máximo de características a considerar para cada división\n",
    "- **Opciones:** None (todas), \"sqrt\" (raíz cuadrada), \"log2\" (logaritmo base 2)\n",
    "- **Útil para:** Reducir correlación entre árboles en Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341e528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRID SEARCH CON MUCHOS PARÁMETROS\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "    \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "    # Descomentar para búsqueda más exhaustiva (¡más lento!):\n",
    "    # \"min_samples_split\": [2, 5, 10],\n",
    "    # \"min_samples_leaf\": [1, 2, 5],\n",
    "    # \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    scoring=\"accuracy\",  # 📝 MODIFICAR: \"accuracy\", \"f1\", \"roc_auc\"\n",
    "    cv=5,                # 📝 MODIFICAR: Número de folds\n",
    "    n_jobs=-1,\n",
    "    verbose=1            # Mostrar progreso\n",
    ")\n",
    "\n",
    "print(\"⏳ Ejecutando búsqueda exhaustiva...\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n✅ Búsqueda completada\")\n",
    "print(f\"\\n🏆 Mejores parámetros: {grid.best_params_}\")\n",
    "print(f\"📊 Mejor accuracy (CV): {grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dcb205",
   "metadata": {},
   "source": [
    "---\n",
    "## 1️⃣8️⃣ PASO 18: Modelo Final Definitivo\n",
    "\n",
    "**Obligatorio:** ✅ SÍ - Entrenar el modelo final con los mejores parámetros encontrados.\n",
    "\n",
    "**📝 IMPORTANTE:** Actualiza los parámetros con los valores de `grid.best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO FINAL CON LOS MEJORES PARÁMETROS\n",
    "# 📝 MODIFICAR: Usa los valores que obtuviste del GridSearch anterior\n",
    "\n",
    "clf_final = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",    # 📝 Actualizar según best_params_\n",
    "    max_depth=8,         # 📝 Actualizar según best_params_\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# ENTRENAR\n",
    "clf_final.fit(X_train, y_train)\n",
    "\n",
    "# EVALUAR\n",
    "acc_final = clf_final.score(X_test, y_test)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"🎯 MODELO FINAL - RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy en test: {acc_final:.4f} ({acc_final*100:.2f}%)\")\n",
    "print(f\"Profundidad del árbol: {clf_final.get_depth()}\")\n",
    "print(f\"Número de hojas: {clf_final.get_n_leaves()}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16222c5",
   "metadata": {},
   "source": [
    "---\n",
    "## 🎓 RESUMEN Y GUÍA RÁPIDA\n",
    "\n",
    "### ✅ Pasos OBLIGATORIOS (flujo mínimo):\n",
    "1. Importar librerías\n",
    "2. Cargar datos\n",
    "3. Dividir datos (train/test)\n",
    "4. Crear y entrenar modelo\n",
    "5. Evaluar modelo\n",
    "\n",
    "### ⚠️ Pasos OPCIONALES pero RECOMENDADOS:\n",
    "- GridSearchCV (optimización de parámetros)\n",
    "- Matriz de confusión y métricas\n",
    "- Visualización del árbol\n",
    "- Importancia de variables\n",
    "\n",
    "### ❌ Pasos OPCIONALES según dataset:\n",
    "- Variables dummy (solo si tienes categóricas)\n",
    "- Escalado (no necesario para árboles)\n",
    "- Graphviz (solo en Colab o con instalación local)\n",
    "\n",
    "### 🔧 Parámetros principales para experimentar:\n",
    "\n",
    "| Parámetro | Valores típicos | Efecto |\n",
    "|-----------|----------------|--------|\n",
    "| `criterion` | \"gini\", \"entropy\" | Método de división |\n",
    "| `max_depth` | 3-10, None | Profundidad del árbol |\n",
    "| `min_samples_split` | 2, 5, 10 | Control de divisiones |\n",
    "| `min_samples_leaf` | 1, 2, 5 | Tamaño mínimo de hojas |\n",
    "| `test_size` | 0.20-0.30 | Proporción de datos test |\n",
    "\n",
    "---\n",
    "\n",
    "## 💡 CONSEJOS PARA MODIFICAR Y EXPERIMENTAR:\n",
    "\n",
    "1. **Para un nuevo dataset:**\n",
    "   - Cambia el nombre del archivo CSV en el Paso 2\n",
    "   - Cambia el nombre de la columna objetivo\n",
    "   - Verifica si tienes variables categóricas (Paso 3)\n",
    "\n",
    "2. **Para mejorar el modelo:**\n",
    "   - Ejecuta GridSearchCV (Paso 7 o 17)\n",
    "   - Usa los mejores parámetros encontrados\n",
    "   - Prueba con diferentes métricas (accuracy, f1, precision)\n",
    "\n",
    "3. **Para datasets pequeños (<1000 filas):**\n",
    "   - Aumenta `test_size` a 0.30-0.40\n",
    "   - Usa CV más alto (cv=10 en GridSearch)\n",
    "   - Limita `max_depth` a 3-5 para evitar sobreajuste\n",
    "\n",
    "4. **Para datasets grandes (>10000 filas):**\n",
    "   - Reduce `test_size` a 0.10-0.20\n",
    "   - Puedes probar árboles más profundos\n",
    "   - Usa `n_jobs=-1` para paralelizar\n",
    "\n",
    "---\n",
    "\n",
    "**¡Listo para experimentar! 🚀**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
